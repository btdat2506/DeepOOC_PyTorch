{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose, Lambda\n",
    "from torch.nn.functional import normalize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.126640500Z",
     "start_time": "2023-10-24T08:24:18.112483800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 2023-10-24 15:24:25,110 | I will output to terminal\n",
      "WARNING 2023-10-24 15:24:25,113 | FOO\n",
      "INFO 2023-10-24 15:24:25,115 | hello\n",
      "WARNING 2023-10-24 15:24:25,117 | BAR\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging.config\n",
    "\n",
    "logging.config.dictConfig({\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": True,\n",
    "    \"formatters\": {\n",
    "        \"default\": {\n",
    "            \"format\": \"{levelname} {asctime} | {message}\",\n",
    "            \"style\": \"{\",\n",
    "        },\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"formatter\": \"default\",\n",
    "            \"stream\": sys.stdout,\n",
    "        }\n",
    "    },\n",
    "    \"root\": {\n",
    "        \"level\": \"DEBUG\",\n",
    "        \"handlers\": [\"console\"],\n",
    "    },\n",
    "})\n",
    "\n",
    "\n",
    "# Get root logger (all other loggers will be derived from this logger's\n",
    "# properties)\n",
    "logger = logging.getLogger()\n",
    "logger.warning(\"I will output to terminal\")  # No output in notebook, goes to terminal\n",
    "\n",
    "# assuming only a single handler has been setup (seems \n",
    "# to be default in notebook), set that handler to go to stdout.\n",
    "# logger.handlers[0].stream = sys.stdout\n",
    "\n",
    "logger.warning(\"FOO\")  # Prints: WARNING:root:FOO\n",
    "logger.info(\"hello\")\n",
    "\n",
    "# Other loggers derive from the root logger, so you can also do:\n",
    "logger2 = logging.getLogger(\"logger2\")\n",
    "logger2.warning(\"BAR\")  # Prints: WARNING:logger2:BAR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.163542100Z",
     "start_time": "2023-10-24T08:24:25.108688600Z"
    }
   },
   "id": "33ad622cc6a8f412"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set hardware\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.165536200Z",
     "start_time": "2023-10-24T08:24:25.134619300Z"
    }
   },
   "id": "f5e3c28b88c23a60"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def GlobalContrastNormalization(tensor: torch.tensor, scale='l2'):\n",
    "    assert scale in ('l1', 'l2')\n",
    "    n_features = int(np.prod(tensor.shape))\n",
    "            \n",
    "    tensor = tensor - torch.mean(tensor)\n",
    "    \n",
    "    if (scale == 'l1'):\n",
    "        tensor = tensor / torch.mean(torch.abs(tensor))\n",
    "    \n",
    "    if (scale == 'l2'):\n",
    "        tensor = tensor / torch.sqrt(torch.sum(tensor ** 2) / n_features)\n",
    "    \n",
    "    return tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.252887300Z",
     "start_time": "2023-10-24T08:24:25.149580400Z"
    }
   },
   "id": "249fc22063ab1e62"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_target_label_idx(labels, targets):\n",
    "    \"\"\"\n",
    "    Get the indices of labels that are included in targets.\n",
    "    :param labels: array of labels\n",
    "    :param targets: list/tuple of target labels\n",
    "    :return: list with indices of target labels\n",
    "    \"\"\"\n",
    "    return [idx for idx, label in enumerate(labels) if label in targets]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.304757400Z",
     "start_time": "2023-10-24T08:24:25.167533Z"
    }
   },
   "id": "2469a5861133f5e1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btdat\\AppData\\Local\\miniconda3\\envs\\Deep_OOC\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "normal_class = 0\n",
    "\n",
    "n_classes = 2\n",
    "normal_classes = tuple([normal_class])\n",
    "outlier_classes = list(range(0, 10))\n",
    "outlier_classes.remove(normal_class)\n",
    "\n",
    "min_max = [(-0.8826567065619495, 9.001545489292527),\n",
    "           (-0.6661464580883915, 20.108062262467364),\n",
    "           (-0.7820454743183202, 11.665100841080346),\n",
    "           (-0.7645772083211267, 12.895051191467457),\n",
    "           (-0.7253923114302238, 12.683235701611533),\n",
    "           (-0.7698501867861425, 13.103278415430502),\n",
    "           (-0.778418217980696, 10.457837397569108),\n",
    "           (-0.7129780970522351, 12.057777597673047),\n",
    "           (-0.8280402650205075, 10.581538445782988),\n",
    "           (-0.7369959242164307, 10.697039838804978)]\n",
    "\n",
    "transform = Compose([ToTensor(), \n",
    "                     Lambda(lambda x: GlobalContrastNormalization(x, scale='l1')), \n",
    "                     Normalize([min_max[normal_class][0]], \n",
    "                               [min_max[normal_class][1] - min_max[normal_class][0]])])\n",
    "target_transform = Lambda(lambda x: int(x in outlier_classes))\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "train_idx_normal = get_target_label_idx(training_data.train_labels.clone().data.cpu().numpy(), normal_classes)\n",
    "train_data = Subset(training_data, train_idx_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.433468700Z",
     "start_time": "2023-10-24T08:24:25.186487400Z"
    }
   },
   "id": "6cccc46b60e019d5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MNIST_LeNet_AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 32\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Encoder: Same as Deep Out-of-Context (OOC) network\n",
    "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(4 * 7 * 7, self.rep_dim, bias=False)\n",
    "        \n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(2, 4, 5, bias=False, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "        self.deconv2 = nn.ConvTranspose2d(4, 8, 5, bias=False, padding=3)\n",
    "        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "        self.deconv3 = nn.ConvTranspose2d(8, 1, 5, bias=False, padding=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(nn.functional.leaky_relu(self.bn1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(nn.functional.leaky_relu(self.bn2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(x.size(0), int(self.rep_dim / 16), 4, 4)\n",
    "        x = nn.functional.interpolate(nn.functional.leaky_relu(x), scale_factor=2)\n",
    "        x = self.deconv1(x)\n",
    "        x = nn.functional.interpolate(nn.functional.leaky_relu(self.bn3(x)), scale_factor=2)\n",
    "        x = self.deconv2(x)\n",
    "        x = nn.functional.interpolate(nn.functional.leaky_relu(self.bn4(x)), scale_factor=2)\n",
    "        x = self.deconv3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.463126Z",
     "start_time": "2023-10-24T08:24:25.303646Z"
    }
   },
   "id": "8818e59caa302ac4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MNIST_LeNet_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rep_dim = 32\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n",
    "        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n",
    "        self.fc1 = nn.Linear(4 * 7 * 7, self.rep_dim, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(nn.functional.leaky_relu(self.bn1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(nn.functional.leaky_relu(self.bn2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.323669800Z"
    }
   },
   "id": "2d279ab1b1f99e26"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Configuration for Pretrain and Train\n",
    "optimizer_name: str = 'adam'\n",
    "lr: float = 0.001\n",
    "n_epochs: int = 150\n",
    "lr_milestones: tuple = ()\n",
    "batch_size: int = 128\n",
    "weight_decay: float = 1e-6\n",
    "n_jobs_dataloader: int = 0\n",
    "\n",
    "ae_net = MNIST_LeNet_AutoEncoder().to(device)\n",
    "net = MNIST_LeNet_Network().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.344872700Z"
    }
   },
   "id": "e7f0e9725fffc4ed"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def AutoEncoder_PreTrain():\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size, num_workers=n_jobs_dataloader)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(ae_net.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=(optimizer_name == 'amsgrad'))\n",
    "    schedular = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_milestones, gamma=0.1)\n",
    "    \n",
    "    logger.info('Starting pretraining...')\n",
    "    start_time = time.time()\n",
    "    ae_net.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        schedular.step()\n",
    "        if epoch in lr_milestones:\n",
    "            logger.info('LR Scheduler: new learning rate is %g' % float(schedular.get_lr()[0]))\n",
    "        loss_epoch = 0.0\n",
    "        n_batches = 0\n",
    "        epoch_start_time = time.time()\n",
    "        for data in train_loader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            # Zero the network parameters gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update network parameters via backpropagation: forward + backward + optimize\n",
    "            outputs = ae_net(inputs)\n",
    "            scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n",
    "            loss = torch.mean(scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_epoch += loss.item()\n",
    "            n_batches += 1\n",
    "            \n",
    "        epoch_train_time = time.time() - epoch_start_time\n",
    "        logger.info('Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'.format(epoch + 1, n_epochs, epoch_train_time, loss_epoch / n_batches))\n",
    "        \n",
    "    pretrain_time = time.time() - start_time\n",
    "    logger.info('Pretraining time: %.3f' % pretrain_time)\n",
    "    logger.info('Finished pretraining.')\n",
    "        \n",
    "# AutoEncoder_PreTrain()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.373153700Z"
    }
   },
   "id": "7400a4e9f9cebfd9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def AutoEncoder_Testing():\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearnex import patch_sklearn\n",
    "    patch_sklearn()\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # Get test data loader\n",
    "    test_loader = DataLoader(test_data, batch_size, num_workers=n_jobs_dataloader)\n",
    "    \n",
    "    # Testing\n",
    "    logger.info('Testing autoencoder...')\n",
    "    loss_epoch = 0.0\n",
    "    n_batches = 0\n",
    "    start_time = time.time()\n",
    "    label_score = []\n",
    "    ae_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = ae_net(inputs)\n",
    "            scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n",
    "            loss = torch.mean(scores)\n",
    "    \n",
    "            # Save triple of (idx, label, score) in a list\n",
    "            label_score += list(zip(labels.cpu().data.numpy().tolist(),\n",
    "                                        scores.cpu().data.numpy().tolist()))\n",
    "    \n",
    "            loss_epoch += loss.item()\n",
    "            n_batches += 1\n",
    "    \n",
    "    logger.info('Test set Loss: {:.8f}'.format(loss_epoch / n_batches))\n",
    "    \n",
    "    labels, scores = zip(*label_score)\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    logger.info('Test set AUC: {:.2f}%'.format(100. * auc))\n",
    "    \n",
    "    test_time = time.time() - start_time\n",
    "    logger.info('Autoencoder testing time: %.3f' % test_time)\n",
    "    logger.info('Finished testing autoencoder.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.404642600Z"
    }
   },
   "id": "3290fcd14f890f8a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Save Pretrain model\n",
    "def save_ae():\n",
    "    ae_net_dict = ae_net.state_dict()\n",
    "    torch.save({'ae_net_dict': ae_net_dict}, 'saved_model/ae_net.tar')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.414967300Z"
    }
   },
   "id": "51813de3f443dbb9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load Pretrain model\n",
    "def load_ae():\n",
    "    model_dict = torch.load('saved_model/ae_net.tar')\n",
    "    ae_net.load_state_dict(model_dict['ae_net_dict'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:24:25.483424500Z",
     "start_time": "2023-10-24T08:24:25.442220300Z"
    }
   },
   "id": "68f19793b3f32d8d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:26:22,104 | Testing autoencoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:26:32,811 | Test set Loss: 150.06465381\n",
      "INFO 2023-10-24 15:26:32,817 | sklearn.metrics.roc_auc_score: running accelerated version on CPU\n",
      "INFO 2023-10-24 15:26:33,234 | Test set AUC: 78.06%\n",
      "INFO 2023-10-24 15:26:33,235 | Autoencoder testing time: 11.131\n",
      "INFO 2023-10-24 15:26:33,235 | Finished testing autoencoder.\n"
     ]
    }
   ],
   "source": [
    "AutoEncoder_Testing()\n",
    "load_ae()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:26:33.274751Z",
     "start_time": "2023-10-24T08:26:22.112636800Z"
    }
   },
   "id": "f7318b939f6ff50e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init Network Weights from Pretraining\n",
    "# def init_network_weights_from_pretraining():\n",
    "\"\"\"Initialize the Deep SVDD network weights from the encoder weights of the pretraining autoencoder.\"\"\"\n",
    "\n",
    "net_dict = net.state_dict()\n",
    "ae_net_dict = ae_net.state_dict()\n",
    "\n",
    "# Filter out decoder network keys\n",
    "ae_net_dict = {k: v for k, v in ae_net_dict.items() if k in net_dict}\n",
    "# Overwrite values in the existing state_dict\n",
    "net_dict.update(ae_net_dict)\n",
    "# Load the new state_dict\n",
    "net.load_state_dict(net_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:26:38.834878900Z",
     "start_time": "2023-10-24T08:26:38.804991Z"
    }
   },
   "id": "8dc0ac95afd4e0f9"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Init Hypersphere\n",
    "R = 0.0     # Hypersphere radius R\n",
    "c = None    # Hypersphere center c\n",
    "\n",
    "R = torch.tensor(R, device=device)\n",
    "# c = torch.tensor(c, device=device)\n",
    "nu: float = 0.1\n",
    "assert (0 < nu) & (nu <= 1), \"For hyperparameter nu, it must hold: 0 < nu <= 1.\"\n",
    "\n",
    "warm_up_n_epochs = 10   # Number of training epochs for soft-boundary Deep SVDD before radius R gets updated\n",
    "\n",
    "objective: str = 'one-class'\n",
    "assert objective in ('one-class', 'soft-boundary'), \"Objective must be either 'one-class' or 'soft-boundary'.\"\n",
    "\n",
    "# Results\n",
    "train_time = None\n",
    "test_auc = None\n",
    "test_time = None\n",
    "test_scores = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:27:10.622953500Z",
     "start_time": "2023-10-24T08:27:10.584496700Z"
    }
   },
   "id": "2e20b43a8ff54724"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def init_center_c(train_loader: DataLoader, eps=0.1):\n",
    "    \"\"\"Initialize hypersphere center c as the mean from an initial forward pass on the data.\"\"\"\n",
    "    n_samples = 0\n",
    "    c = torch.zeros(net.rep_dim, device=device)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            # get the inputs of the batch\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = net(inputs)\n",
    "            n_samples += outputs.shape[0]\n",
    "            c += torch.sum(outputs, dim=0)\n",
    "\n",
    "    c /= n_samples\n",
    "\n",
    "    # If c_i is too close to 0, set to +-eps. Reason: a zero unit can be trivially matched with zero weights.\n",
    "    c[(abs(c) < eps) & (c < 0)] = -eps\n",
    "    c[(abs(c) < eps) & (c > 0)] = eps\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def get_radius(dist: torch.Tensor, nu: float):\n",
    "    \"\"\"Optimally solve for radius R via the (1-nu)-quantile of distances.\"\"\"\n",
    "    return np.quantile(np.sqrt(dist.clone().data.cpu().numpy()), 1 - nu)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:27:11.113440800Z",
     "start_time": "2023-10-24T08:27:11.074551400Z"
    }
   },
   "id": "c9396757fd2f37d0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:27:39,684 | Initializing center c...\n",
      "INFO 2023-10-24 15:27:45,995 | Center c initialized.\n",
      "INFO 2023-10-24 15:27:45,995 | Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btdat\\AppData\\Local\\miniconda3\\envs\\Deep_OOC\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:27:54,723 |   Epoch 1/150\t Time: 8.728\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:03,488 |   Epoch 2/150\t Time: 8.763\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:09,580 |   Epoch 3/150\t Time: 6.093\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:15,329 |   Epoch 4/150\t Time: 5.747\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:22,274 |   Epoch 5/150\t Time: 6.945\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:28,487 |   Epoch 6/150\t Time: 6.213\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:36,007 |   Epoch 7/150\t Time: 7.518\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:41,920 |   Epoch 8/150\t Time: 5.912\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:47,318 |   Epoch 9/150\t Time: 5.397\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:52,684 |   Epoch 10/150\t Time: 5.366\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:28:58,147 |   Epoch 11/150\t Time: 5.462\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:03,701 |   Epoch 12/150\t Time: 5.553\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:08,937 |   Epoch 13/150\t Time: 5.235\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:15,442 |   Epoch 14/150\t Time: 6.499\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:20,875 |   Epoch 15/150\t Time: 5.432\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:26,209 |   Epoch 16/150\t Time: 5.333\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:33,587 |   Epoch 17/150\t Time: 7.377\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:38,980 |   Epoch 18/150\t Time: 5.393\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:44,420 |   Epoch 19/150\t Time: 5.438\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:49,705 |   Epoch 20/150\t Time: 5.283\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:29:55,314 |   Epoch 21/150\t Time: 5.610\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:00,754 |   Epoch 22/150\t Time: 5.440\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:06,065 |   Epoch 23/150\t Time: 5.311\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:12,616 |   Epoch 24/150\t Time: 6.550\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:18,913 |   Epoch 25/150\t Time: 6.295\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:24,744 |   Epoch 26/150\t Time: 5.830\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:30,630 |   Epoch 27/150\t Time: 5.884\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:36,284 |   Epoch 28/150\t Time: 5.654\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:41,774 |   Epoch 29/150\t Time: 5.490\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:49,413 |   Epoch 30/150\t Time: 7.639\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:30:56,025 |   Epoch 31/150\t Time: 6.610\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:03,441 |   Epoch 32/150\t Time: 7.417\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:08,873 |   Epoch 33/150\t Time: 5.430\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:14,205 |   Epoch 34/150\t Time: 5.332\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:19,494 |   Epoch 35/150\t Time: 5.288\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:24,721 |   Epoch 36/150\t Time: 5.227\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:29,987 |   Epoch 37/150\t Time: 5.265\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:35,345 |   Epoch 38/150\t Time: 5.356\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:31:43,654 |   Epoch 39/150\t Time: 8.307\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:32:29,817 |   Epoch 40/150\t Time: 46.157\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:03,137 |   Epoch 41/150\t Time: 33.319\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:10,849 |   Epoch 42/150\t Time: 7.710\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:25,015 |   Epoch 43/150\t Time: 14.165\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:35,993 |   Epoch 44/150\t Time: 10.978\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:43,114 |   Epoch 45/150\t Time: 7.119\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:48,568 |   Epoch 46/150\t Time: 5.454\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:54,126 |   Epoch 47/150\t Time: 5.556\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:33:59,708 |   Epoch 48/150\t Time: 5.580\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:05,135 |   Epoch 49/150\t Time: 5.425\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:10,424 |   Epoch 50/150\t Time: 5.289\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:15,926 |   Epoch 51/150\t Time: 5.502\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:25,655 |   Epoch 52/150\t Time: 9.727\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:33,363 |   Epoch 53/150\t Time: 7.707\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:38,991 |   Epoch 54/150\t Time: 5.627\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:44,279 |   Epoch 55/150\t Time: 5.287\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:49,615 |   Epoch 56/150\t Time: 5.333\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:34:55,305 |   Epoch 57/150\t Time: 5.690\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:02,510 |   Epoch 58/150\t Time: 7.205\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:11,113 |   Epoch 59/150\t Time: 8.601\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:16,370 |   Epoch 60/150\t Time: 5.249\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:21,674 |   Epoch 61/150\t Time: 5.305\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:27,264 |   Epoch 62/150\t Time: 5.590\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:33,493 |   Epoch 63/150\t Time: 6.229\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:39,934 |   Epoch 64/150\t Time: 6.441\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:45,864 |   Epoch 65/150\t Time: 5.930\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:52,442 |   Epoch 66/150\t Time: 6.578\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:35:58,853 |   Epoch 67/150\t Time: 6.410\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:06,721 |   Epoch 68/150\t Time: 7.867\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:13,816 |   Epoch 69/150\t Time: 7.094\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:20,022 |   Epoch 70/150\t Time: 6.205\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:25,760 |   Epoch 71/150\t Time: 5.737\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:31,803 |   Epoch 72/150\t Time: 6.041\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:37,618 |   Epoch 73/150\t Time: 5.815\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:43,235 |   Epoch 74/150\t Time: 5.617\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:48,986 |   Epoch 75/150\t Time: 5.752\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:36:54,723 |   Epoch 76/150\t Time: 5.737\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:00,393 |   Epoch 77/150\t Time: 5.669\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:06,027 |   Epoch 78/150\t Time: 5.633\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:16,057 |   Epoch 79/150\t Time: 10.028\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:23,200 |   Epoch 80/150\t Time: 7.143\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:33,371 |   Epoch 81/150\t Time: 10.171\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:39,179 |   Epoch 82/150\t Time: 5.806\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:45,435 |   Epoch 83/150\t Time: 6.256\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:37:54,642 |   Epoch 84/150\t Time: 9.206\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:04,984 |   Epoch 85/150\t Time: 10.341\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:11,235 |   Epoch 86/150\t Time: 6.249\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:17,137 |   Epoch 87/150\t Time: 5.895\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:23,606 |   Epoch 88/150\t Time: 6.469\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:32,689 |   Epoch 89/150\t Time: 9.076\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:41,499 |   Epoch 90/150\t Time: 8.808\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:49,537 |   Epoch 91/150\t Time: 8.037\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:38:55,804 |   Epoch 92/150\t Time: 6.267\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:01,492 |   Epoch 93/150\t Time: 5.688\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:07,321 |   Epoch 94/150\t Time: 5.828\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:12,542 |   Epoch 95/150\t Time: 5.219\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:18,125 |   Epoch 96/150\t Time: 5.582\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:24,565 |   Epoch 97/150\t Time: 6.439\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:31,140 |   Epoch 98/150\t Time: 6.575\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:37,145 |   Epoch 99/150\t Time: 6.004\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:43,211 |   Epoch 100/150\t Time: 6.065\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:50,674 |   Epoch 101/150\t Time: 7.462\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:39:58,760 |   Epoch 102/150\t Time: 8.085\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:08,586 |   Epoch 103/150\t Time: 9.824\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:15,006 |   Epoch 104/150\t Time: 6.418\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:23,746 |   Epoch 105/150\t Time: 8.740\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:29,473 |   Epoch 106/150\t Time: 5.726\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:34,704 |   Epoch 107/150\t Time: 5.231\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:40,533 |   Epoch 108/150\t Time: 5.828\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:46,658 |   Epoch 109/150\t Time: 6.122\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:54,041 |   Epoch 110/150\t Time: 7.383\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:40:59,553 |   Epoch 111/150\t Time: 5.511\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:06,433 |   Epoch 112/150\t Time: 6.878\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:15,570 |   Epoch 113/150\t Time: 9.136\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:23,384 |   Epoch 114/150\t Time: 7.814\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:29,496 |   Epoch 115/150\t Time: 6.112\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:35,243 |   Epoch 116/150\t Time: 5.746\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:44,855 |   Epoch 117/150\t Time: 9.608\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:50,473 |   Epoch 118/150\t Time: 5.618\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:41:56,524 |   Epoch 119/150\t Time: 6.050\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:02,139 |   Epoch 120/150\t Time: 5.613\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:07,961 |   Epoch 121/150\t Time: 5.821\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:13,136 |   Epoch 122/150\t Time: 5.175\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:18,533 |   Epoch 123/150\t Time: 5.396\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:23,778 |   Epoch 124/150\t Time: 5.245\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:29,013 |   Epoch 125/150\t Time: 5.234\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:34,327 |   Epoch 126/150\t Time: 5.314\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:39,609 |   Epoch 127/150\t Time: 5.281\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:45,133 |   Epoch 128/150\t Time: 5.521\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:42:51,991 |   Epoch 129/150\t Time: 6.857\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:00,294 |   Epoch 130/150\t Time: 8.302\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:06,174 |   Epoch 131/150\t Time: 5.878\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:11,554 |   Epoch 132/150\t Time: 5.379\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:18,717 |   Epoch 133/150\t Time: 7.163\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:24,532 |   Epoch 134/150\t Time: 5.815\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:31,014 |   Epoch 135/150\t Time: 6.481\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:36,432 |   Epoch 136/150\t Time: 5.418\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:43,053 |   Epoch 137/150\t Time: 6.620\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:49,507 |   Epoch 138/150\t Time: 6.453\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:43:55,512 |   Epoch 139/150\t Time: 6.004\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:02,502 |   Epoch 140/150\t Time: 6.989\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:09,156 |   Epoch 141/150\t Time: 6.652\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:19,494 |   Epoch 142/150\t Time: 10.338\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:27,025 |   Epoch 143/150\t Time: 7.529\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:35,659 |   Epoch 144/150\t Time: 8.633\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:42,595 |   Epoch 145/150\t Time: 6.932\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:49,044 |   Epoch 146/150\t Time: 6.448\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:54,353 |   Epoch 147/150\t Time: 5.308\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:44:59,790 |   Epoch 148/150\t Time: 5.437\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:45:05,209 |   Epoch 149/150\t Time: 5.419\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:45:11,463 |   Epoch 150/150\t Time: 6.252\t Loss: 7.25245537\n",
      "INFO 2023-10-24 15:45:11,464 | Training time: 1045.469\n",
      "INFO 2023-10-24 15:45:11,465 | Finished training.\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "# Get train data loader\n",
    "train_loader = DataLoader(train_data, batch_size, num_workers=n_jobs_dataloader)\n",
    "    \n",
    "# Set optimizer (Adam optimizer for now)\n",
    "optimizer = torch.optim.Adam(ae_net.parameters(), lr=lr, weight_decay=weight_decay, amsgrad=(optimizer_name == 'amsgrad'))\n",
    "\n",
    "# Set learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_milestones, gamma=0.1)\n",
    "\n",
    "# Initialize hypersphere center c (if c not loaded)\n",
    "if c is None:\n",
    "    logger.info('Initializing center c...')\n",
    "    c = init_center_c(train_loader)\n",
    "    logger.info('Center c initialized.')\n",
    "\n",
    "# Training\n",
    "logger.info('Starting training...')\n",
    "start_time = time.time()\n",
    "net.train()\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    scheduler.step()\n",
    "    if epoch in lr_milestones:\n",
    "        logger.info('  LR scheduler: new learning rate is %g' % float(scheduler.get_lr()[0]))\n",
    "\n",
    "    loss_epoch = 0.0\n",
    "    n_batches = 0\n",
    "    epoch_start_time = time.time()\n",
    "    for data in train_loader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Zero the network parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update network parameters via backpropagation: forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        dist = torch.sum((outputs - c) ** 2, dim=1)\n",
    "        if objective == 'soft-boundary':\n",
    "            scores = dist - R ** 2\n",
    "            loss = R ** 2 + (1 / nu) * torch.mean(torch.max(torch.zeros_like(scores), scores))\n",
    "        else:\n",
    "            loss = torch.mean(dist)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update hypersphere radius R on mini-batch distances\n",
    "        if (objective == 'soft-boundary') and (epoch >= warm_up_n_epochs):\n",
    "            R.data = torch.tensor(get_radius(dist, nu), device=device)\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    # log epoch statistics\n",
    "    epoch_train_time = time.time() - epoch_start_time\n",
    "    logger.info('  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'\n",
    "                .format(epoch + 1, n_epochs, epoch_train_time, loss_epoch / n_batches))\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "logger.info('Training time: %.3f' % train_time)\n",
    "\n",
    "logger.info('Finished training.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:45:11.494056200Z",
     "start_time": "2023-10-24T08:27:39.683161Z"
    }
   },
   "id": "a0011a948dc6ddeb"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "#end train\n",
    "R = float(R.cpu().data.numpy())\n",
    "c = c.cpu().data.numpy().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:45:31.747638200Z",
     "start_time": "2023-10-24T08:45:31.712052400Z"
    }
   },
   "id": "3bb776e5ba57056f"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    net_dict = net.state_dict()\n",
    "    ae_net_dict = ae_net.state_dict()\n",
    "    torch.save({'R': R, 'c': c, 'net_dict': net_dict, 'ae_net_dict': ae_net_dict}, 'saved_model/model.tar')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:27:19.502920600Z",
     "start_time": "2023-10-24T08:27:19.464677Z"
    }
   },
   "id": "5d92d16f8d7fc770"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "save_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:45:40.204488400Z",
     "start_time": "2023-10-24T08:45:40.113337300Z"
    }
   },
   "id": "c945b45b6ce9944"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model():\n",
    "    model_dict = torch.load('saved_model/model.tar')\n",
    "    \n",
    "    R = model_dict['R']\n",
    "    c = model_dict['c']\n",
    "    net.load_state_dict(model_dict['net_dict'])\n",
    "    ae_net.load_state_dict(model_dict['ae_net_dict'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:45:45.954560600Z",
     "start_time": "2023-10-24T08:45:45.924786800Z"
    }
   },
   "id": "2353aff6627214ac"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "load_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:45:54.570692400Z",
     "start_time": "2023-10-24T08:45:54.485379900Z"
    }
   },
   "id": "b719b6f8ea065f85"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:55:41,775 | Starting testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "C:\\Users\\btdat\\AppData\\Local\\Temp\\ipykernel_17032\\4107340890.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R = torch.tensor(R, device=device)\n",
      "C:\\Users\\btdat\\AppData\\Local\\Temp\\ipykernel_17032\\4107340890.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c = torch.tensor(c, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:55:56,277 | Testing time: 14.499\n",
      "INFO 2023-10-24 15:55:56,288 | sklearn.metrics.roc_auc_score: running accelerated version on CPU\n",
      "INFO 2023-10-24 15:55:56,293 | Test set AUC: 71.13%\n",
      "INFO 2023-10-24 15:55:56,295 | Finished testing.\n"
     ]
    }
   ],
   "source": [
    "# def test(self, dataset: BaseADDataset, net: BaseNet):\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "R = torch.tensor(R, device=device)\n",
    "c = torch.tensor(c, device=device)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Get test data loader\n",
    "test_loader = DataLoader(test_data, batch_size, num_workers=n_jobs_dataloader)\n",
    "\n",
    "# Testing\n",
    "logger.info('Starting testing...')\n",
    "start_time = time.time()\n",
    "label_score = []\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        dist = torch.sum((outputs - c) ** 2, dim=1)\n",
    "        if objective == 'soft-boundary':\n",
    "            scores = dist - R ** 2\n",
    "        else:\n",
    "            scores = dist\n",
    "\n",
    "        # Save triples of (idx, label, score) in a list\n",
    "        label_score += list(zip(labels.cpu().data.numpy().tolist(),\n",
    "                                    scores.cpu().data.numpy().tolist()))\n",
    "\n",
    "test_time = time.time() - start_time\n",
    "logger.info('Testing time: %.3f' % test_time)\n",
    "\n",
    "test_scores = label_score\n",
    "\n",
    "# Compute AUC\n",
    "labels, scores = zip(*label_score)\n",
    "labels = np.array(labels)\n",
    "scores = np.array(scores)\n",
    "\n",
    "test_auc = roc_auc_score(labels, scores)\n",
    "logger.info('Test set AUC: {:.2f}%'.format(100. * test_auc))\n",
    "\n",
    "logger.info('Finished testing.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:55:56.388428800Z",
     "start_time": "2023-10-24T08:55:41.779135Z"
    }
   },
   "id": "53d28eb8a4df5446"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2023-10-24 15:58:35,264 | Test set Accuracy: 9.80%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(labels, (scores > 40).astype(int))\n",
    "logger.info('Test set Accuracy: {:.2f}%'.format(100. * test_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:58:35.342735Z",
     "start_time": "2023-10-24T08:58:35.264063400Z"
    }
   },
   "id": "d5109bbf92d0a9d3"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.),\n tensor([ 0.1000, -0.1000,  0.1000, -0.1000,  0.1000,  0.1000, -0.1000,  0.1000,\n         -0.1000, -0.1000, -0.1000,  0.1000,  0.1000,  0.1000,  0.1000,  0.1000,\n         -0.1000,  0.1000,  0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,\n          0.1000,  0.1000, -0.1000, -0.1000, -0.1000, -0.1000, -0.1000,  0.1000]))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R, c"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:56:44.103717900Z",
     "start_time": "2023-10-24T08:56:43.925226700Z"
    }
   },
   "id": "a6c8a6cfa250624f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "747ff985458ff22c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
